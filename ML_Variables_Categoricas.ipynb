{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables categóricas\n",
    "* Hay muchos datos no numéricos por ahí. \n",
    "* Aquí se explican tres enfoques de cómo gestionar estas variables para el aprendizaje automático.\n",
    "\n",
    "**Introducción**\n",
    "* Una variable categórica toma sólo un número limitado y normalmente fijo de valores discretos.\n",
    "* Las variables categóricas pueden ser de dos tipos: **nominales** y **ordinales**\n",
    "  * **Variables Nominales**: Estas no tienen un orden intrínseco. Por ejemplo, colores como \"rojo\", \"verde\" y \"azul\".\n",
    "  * **Variables Ordinales**: Estas tienen un orden natural. Por ejemplo, tamaños de camiseta como \"pequeño\", \"mediano\" y \"grande\".\n",
    "Consideremos una encuesta que pregunte la frecuencia con que se desayuna y ofrece cuatro opciones:\n",
    " * \"**Nunca**\",\n",
    " * \"**Rara vez**\",\n",
    " * \"**La mayoría de los días**\"\n",
    " * \"**Todos los días**\".\n",
    "* En este caso, los datos son categóricos, porque **las respuestas se clasifican en un conjunto fijo de categorías.**\n",
    "* Si las personas respondieran a una encuesta sobre qué marca de automóvil poseen, las respuestas se clasificarían en categorías como:\n",
    "  * \"**Honda**\",\n",
    "  * \"**Toyota**\"\n",
    "  * \"**Ford**\".\n",
    "* En este caso, los datos también son categóricos.\n",
    "* **Advertencia**: Recibirá un error si intenta conectar estas variables en la mayoría de los modelos de aprendizaje automático en Python sin preprocesarlas primero.\n",
    "* En este apartado compararemos tres enfoques que se pueden utilizar para preparar los datos categóricos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enfoques para abordar Variables categóricas\n",
    "\n",
    "## 1.Eliminar variables categóricas\n",
    "* El enfoque más sencillo para tratar con variables categóricas es simplemente eliminarlas del conjunto de datos.\n",
    "* Este enfoque sólo funcionará bien si las columnas no contienen información útil.\n",
    "\n",
    "## 2.Codificación ordinal: OrdinalEncoder()\n",
    "* El método **OrdinalEncoder** de scikit-learn se utiliza para **convertir variables categóricas ordinales** en **números enteros** que reflejan su orden.\n",
    "* Por ejemplo, si tienes una variable ordinal con los valores [\"bajo\", \"medio\", \"alto\"], el OrdinalEncoder puede mapear estos valores a [0, 1, 2], respectivamente. Este enfoque es útil porque conserva la relación de orden entre las categorías.\n",
    "\n",
    "\n",
    "* La codificación ordinal \"**OrdinalEncoder**\" de scikit-learn se utiliza para convertir variables categóricas ordinales en números enteros que reflejan su orden, asignando **cada valor único** a un número entero diferente.\n",
    "* Siguiendo con el ejemplo de la encuesta [\"nunca\", \"rara vez\", \"La mayoría de las verces\", \"Todos los días\"] se puede mapear a los valores a [0, 1, 2, 3],:\n",
    "  * asigna **0** a \"**Nunca**\",\n",
    "  * asigna **1** a \"**Rara vez**\",\n",
    "  * asigna **2** a \"**La mayoría de los días**\"\n",
    "  * asigna **3** a \"**Todos los días**\".\n",
    "* Este enfoque **supone un orden de las categorías**: \"Nunca\" (0) < \"Rara vez\" (1) < \"La mayoría de los días\" (2) < \"Todos los días\" (3).\n",
    "* Esta suposición tiene sentido en este ejemplo, porque existe una clasificación indiscutible de las categorías.\n",
    "* **Recordar que No todas las variables categóricas tienen un orden claro en los valores**. Las que lo tienen se denominan como **variables ordinales**.\n",
    "* Para los modelos basados en árboles (como árboles de decisión y bosques aleatorios), se puede esperar que la codificación ordinal funcione bien con variables ordinales.\n",
    "\n",
    "## 3.Codificación en one-hot: One-HotEncoder()\n",
    "* La codificación One-Hot es una técnica utilizada para convertir **variables categóricas nominales** en una forma que puede ser proporcionada a algoritmos de aprendizaje automático para hacer una mejor predicción.\n",
    "* La idea es transformar cada categoría en una nueva columna binaria (dummy variable), que tiene un valor de 1 si la instancia pertenece a esa categoría, y 0 en caso contrario.\n",
    "* La codificación **one-hot** crea nuevas columnas que indican la presencia (o ausencia) de cada valor posible en los datos originales.\n",
    "Para entender esto, ilustremos un ejemplo.\n",
    "* Supongase un dataset, donde \"**Color**\" es una variable categórica nominal con tres categorías: [\"**Rojo**\", \"**Amarillo**\", \"**Verde**\"].\n",
    "* El One-Hot Encoding transformaría esta variable en tres columnas:\n",
    "  * Color_rojo\n",
    "  * Color_amarillo\n",
    "  * Color_verde\n",
    "* La codificación one-hot correspondiente contiene una columna para cada valor posible (rojo, amarillo, verde)\n",
    "* Cada fila representa una observación y, en cada fila, solo una de las columnas binarias tendrá un valor de 1, indicando la categoría a la que pertenece esa observación.\n",
    "* Siempre que el valor original fuera \"Rojo\", ponemos un 1 en la columna \"Rojo\"; si el valor original era \"Amarillo\", ponemos un 1 en la columna \"Amarillo\", y así sucesivamente.\n",
    "* Este enfoque de codificación binaria garantiza que cada categoría tenga una representación única y distintiva en el conjunto de datos codificado\n",
    "* A diferencia de la codificación ordinal, **la codificación one-hot no supone un ordenamiento** de las categorías.\n",
    "* Por lo tanto, puede esperar que este enfoque funcione particularmente bien si no hay un orden claro en los datos categóricos (por ejemplo, \"Rojo\" no es ni más ni menos que \"Amarillo\").\n",
    "* Recordemos que las variables categóricas sin una clasificación intrínseca se denominan **variables nominales**.\n",
    "* La codificación one-hot generalmente no funciona bien si la variable categórica toma una gran cantidad de valores (es decir, generalmente no la usará para variables que toman más de 15 valores diferentes).\n",
    "\n",
    "¿Por qué se llama \"One-Hot\"?\n",
    "* El término \"one-hot\" se refiere a la representación en la que \"uno\" (one) indica la presencia de una categoría específica y \"cero\" se usa en todas las otras categorías, es decir, solo una de las variables es \"hot\" (activa) a la vez. **one-hot = una - activa**\n",
    "\n",
    "**Conclusion**\n",
    "* Para variables ordinales(suponen orden entre ellas), funciona la codificación ordinal\n",
    "* Para variables nominales (No suponen orden entre ellas), funciona la codificación one-hot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leer los datos\n",
    "X = pd.read_csv('train.csv', index_col='Id')\n",
    "X_test = pd.read_csv('test.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Los conjuntos de entrenamiento y validación se cargaran en **X_train, X_valid, y_train e y_valid**.\n",
    "* El conjunto de prueba se carga en **X_test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1460 entries, 1 to 1460\n",
      "Data columns (total 80 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MSSubClass     1460 non-null   int64  \n",
      " 1   MSZoning       1460 non-null   object \n",
      " 2   LotFrontage    1201 non-null   float64\n",
      " 3   LotArea        1460 non-null   int64  \n",
      " 4   Street         1460 non-null   object \n",
      " 5   Alley          91 non-null     object \n",
      " 6   LotShape       1460 non-null   object \n",
      " 7   LandContour    1460 non-null   object \n",
      " 8   Utilities      1460 non-null   object \n",
      " 9   LotConfig      1460 non-null   object \n",
      " 10  LandSlope      1460 non-null   object \n",
      " 11  Neighborhood   1460 non-null   object \n",
      " 12  Condition1     1460 non-null   object \n",
      " 13  Condition2     1460 non-null   object \n",
      " 14  BldgType       1460 non-null   object \n",
      " 15  HouseStyle     1460 non-null   object \n",
      " 16  OverallQual    1460 non-null   int64  \n",
      " 17  OverallCond    1460 non-null   int64  \n",
      " 18  YearBuilt      1460 non-null   int64  \n",
      " 19  YearRemodAdd   1460 non-null   int64  \n",
      " 20  RoofStyle      1460 non-null   object \n",
      " 21  RoofMatl       1460 non-null   object \n",
      " 22  Exterior1st    1460 non-null   object \n",
      " 23  Exterior2nd    1460 non-null   object \n",
      " 24  MasVnrType     1452 non-null   object \n",
      " 25  MasVnrArea     1452 non-null   float64\n",
      " 26  ExterQual      1460 non-null   object \n",
      " 27  ExterCond      1460 non-null   object \n",
      " 28  Foundation     1460 non-null   object \n",
      " 29  BsmtQual       1423 non-null   object \n",
      " 30  BsmtCond       1423 non-null   object \n",
      " 31  BsmtExposure   1422 non-null   object \n",
      " 32  BsmtFinType1   1423 non-null   object \n",
      " 33  BsmtFinSF1     1460 non-null   int64  \n",
      " 34  BsmtFinType2   1422 non-null   object \n",
      " 35  BsmtFinSF2     1460 non-null   int64  \n",
      " 36  BsmtUnfSF      1460 non-null   int64  \n",
      " 37  TotalBsmtSF    1460 non-null   int64  \n",
      " 38  Heating        1460 non-null   object \n",
      " 39  HeatingQC      1460 non-null   object \n",
      " 40  CentralAir     1460 non-null   object \n",
      " 41  Electrical     1459 non-null   object \n",
      " 42  1stFlrSF       1460 non-null   int64  \n",
      " 43  2ndFlrSF       1460 non-null   int64  \n",
      " 44  LowQualFinSF   1460 non-null   int64  \n",
      " 45  GrLivArea      1460 non-null   int64  \n",
      " 46  BsmtFullBath   1460 non-null   int64  \n",
      " 47  BsmtHalfBath   1460 non-null   int64  \n",
      " 48  FullBath       1460 non-null   int64  \n",
      " 49  HalfBath       1460 non-null   int64  \n",
      " 50  BedroomAbvGr   1460 non-null   int64  \n",
      " 51  KitchenAbvGr   1460 non-null   int64  \n",
      " 52  KitchenQual    1460 non-null   object \n",
      " 53  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 54  Functional     1460 non-null   object \n",
      " 55  Fireplaces     1460 non-null   int64  \n",
      " 56  FireplaceQu    770 non-null    object \n",
      " 57  GarageType     1379 non-null   object \n",
      " 58  GarageYrBlt    1379 non-null   float64\n",
      " 59  GarageFinish   1379 non-null   object \n",
      " 60  GarageCars     1460 non-null   int64  \n",
      " 61  GarageArea     1460 non-null   int64  \n",
      " 62  GarageQual     1379 non-null   object \n",
      " 63  GarageCond     1379 non-null   object \n",
      " 64  PavedDrive     1460 non-null   object \n",
      " 65  WoodDeckSF     1460 non-null   int64  \n",
      " 66  OpenPorchSF    1460 non-null   int64  \n",
      " 67  EnclosedPorch  1460 non-null   int64  \n",
      " 68  3SsnPorch      1460 non-null   int64  \n",
      " 69  ScreenPorch    1460 non-null   int64  \n",
      " 70  PoolArea       1460 non-null   int64  \n",
      " 71  PoolQC         7 non-null      object \n",
      " 72  Fence          281 non-null    object \n",
      " 73  MiscFeature    54 non-null     object \n",
      " 74  MiscVal        1460 non-null   int64  \n",
      " 75  MoSold         1460 non-null   int64  \n",
      " 76  YrSold         1460 non-null   int64  \n",
      " 77  SaleType       1460 non-null   object \n",
      " 78  SaleCondition  1460 non-null   object \n",
      " 79  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(34), object(43)\n",
      "memory usage: 923.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# 1. Revisemos nuestro dataframe X, X_test\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se observa un dataset con 1460 entradas y 80 columnas.\n",
    "* Existen columnas con valores nulos,\n",
    "* 37 variables numéricas(tipo=int64, float64)\n",
    "* 43 variables categóricas(tipo=object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1459 entries, 1461 to 2919\n",
      "Data columns (total 79 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MSSubClass     1459 non-null   int64  \n",
      " 1   MSZoning       1455 non-null   object \n",
      " 2   LotFrontage    1232 non-null   float64\n",
      " 3   LotArea        1459 non-null   int64  \n",
      " 4   Street         1459 non-null   object \n",
      " 5   Alley          107 non-null    object \n",
      " 6   LotShape       1459 non-null   object \n",
      " 7   LandContour    1459 non-null   object \n",
      " 8   Utilities      1457 non-null   object \n",
      " 9   LotConfig      1459 non-null   object \n",
      " 10  LandSlope      1459 non-null   object \n",
      " 11  Neighborhood   1459 non-null   object \n",
      " 12  Condition1     1459 non-null   object \n",
      " 13  Condition2     1459 non-null   object \n",
      " 14  BldgType       1459 non-null   object \n",
      " 15  HouseStyle     1459 non-null   object \n",
      " 16  OverallQual    1459 non-null   int64  \n",
      " 17  OverallCond    1459 non-null   int64  \n",
      " 18  YearBuilt      1459 non-null   int64  \n",
      " 19  YearRemodAdd   1459 non-null   int64  \n",
      " 20  RoofStyle      1459 non-null   object \n",
      " 21  RoofMatl       1459 non-null   object \n",
      " 22  Exterior1st    1458 non-null   object \n",
      " 23  Exterior2nd    1458 non-null   object \n",
      " 24  MasVnrType     1443 non-null   object \n",
      " 25  MasVnrArea     1444 non-null   float64\n",
      " 26  ExterQual      1459 non-null   object \n",
      " 27  ExterCond      1459 non-null   object \n",
      " 28  Foundation     1459 non-null   object \n",
      " 29  BsmtQual       1415 non-null   object \n",
      " 30  BsmtCond       1414 non-null   object \n",
      " 31  BsmtExposure   1415 non-null   object \n",
      " 32  BsmtFinType1   1417 non-null   object \n",
      " 33  BsmtFinSF1     1458 non-null   float64\n",
      " 34  BsmtFinType2   1417 non-null   object \n",
      " 35  BsmtFinSF2     1458 non-null   float64\n",
      " 36  BsmtUnfSF      1458 non-null   float64\n",
      " 37  TotalBsmtSF    1458 non-null   float64\n",
      " 38  Heating        1459 non-null   object \n",
      " 39  HeatingQC      1459 non-null   object \n",
      " 40  CentralAir     1459 non-null   object \n",
      " 41  Electrical     1459 non-null   object \n",
      " 42  1stFlrSF       1459 non-null   int64  \n",
      " 43  2ndFlrSF       1459 non-null   int64  \n",
      " 44  LowQualFinSF   1459 non-null   int64  \n",
      " 45  GrLivArea      1459 non-null   int64  \n",
      " 46  BsmtFullBath   1457 non-null   float64\n",
      " 47  BsmtHalfBath   1457 non-null   float64\n",
      " 48  FullBath       1459 non-null   int64  \n",
      " 49  HalfBath       1459 non-null   int64  \n",
      " 50  BedroomAbvGr   1459 non-null   int64  \n",
      " 51  KitchenAbvGr   1459 non-null   int64  \n",
      " 52  KitchenQual    1458 non-null   object \n",
      " 53  TotRmsAbvGrd   1459 non-null   int64  \n",
      " 54  Functional     1457 non-null   object \n",
      " 55  Fireplaces     1459 non-null   int64  \n",
      " 56  FireplaceQu    729 non-null    object \n",
      " 57  GarageType     1383 non-null   object \n",
      " 58  GarageYrBlt    1381 non-null   float64\n",
      " 59  GarageFinish   1381 non-null   object \n",
      " 60  GarageCars     1458 non-null   float64\n",
      " 61  GarageArea     1458 non-null   float64\n",
      " 62  GarageQual     1381 non-null   object \n",
      " 63  GarageCond     1381 non-null   object \n",
      " 64  PavedDrive     1459 non-null   object \n",
      " 65  WoodDeckSF     1459 non-null   int64  \n",
      " 66  OpenPorchSF    1459 non-null   int64  \n",
      " 67  EnclosedPorch  1459 non-null   int64  \n",
      " 68  3SsnPorch      1459 non-null   int64  \n",
      " 69  ScreenPorch    1459 non-null   int64  \n",
      " 70  PoolArea       1459 non-null   int64  \n",
      " 71  PoolQC         3 non-null      object \n",
      " 72  Fence          290 non-null    object \n",
      " 73  MiscFeature    51 non-null     object \n",
      " 74  MiscVal        1459 non-null   int64  \n",
      " 75  MoSold         1459 non-null   int64  \n",
      " 76  YrSold         1459 non-null   int64  \n",
      " 77  SaleType       1458 non-null   object \n",
      " 78  SaleCondition  1459 non-null   object \n",
      "dtypes: float64(11), int64(25), object(43)\n",
      "memory usage: 911.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Revisemos X_test\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se observa un dataset con 1459 entradas y 79 columnas.\n",
    "* Existen columnas con valores nulos,\n",
    "* 36 variables numéricas(25 int64 + 11 float64)\n",
    "* 43 variables categóricas(tipo=object)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columnas con valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de utilidad para contar columnas con valores nulos\n",
    "def informar_columnas_nulas(dataframe, nombre_dataframe):\n",
    "    # Contamos las columnas que tienen al menos un valor nulo\n",
    "    columnas_con_nulos = dataframe.isnull().any(axis=0).sum()\n",
    "\n",
    "    # Imprimimos el resultado\n",
    "    print(f\"El dataframe {nombre_dataframe} tiene {columnas_con_nulos} columnas con valores nulos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataframe X tiene 19 columnas con valores nulos.\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Contar columnas con valores faltantes en X\n",
    "informar_columnas_nulas(X, \"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataframe X_test tiene 33 columnas con valores nulos.\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Contar columnas con valores faltantes en X_test\n",
    "informar_columnas_nulas(X_test, \"X_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar valores faltantes en la variable objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En el df X, se eliminan filas con valores faltantes en la variable objetivo \"SalePrice\"\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definción de variable objetivo y predictoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la varaible objetivo\n",
    "y = X.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar varaible objetivo de las predictoras\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestión de Valores faltantes\n",
    "* En este caso, usaremos el enfoque más simple: Eliminar columnas con valores faltantes tanto en X como en X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotFrontage',\n",
       " 'Alley',\n",
       " 'MasVnrType',\n",
       " 'MasVnrArea',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Electrical',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageYrBlt',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PoolQC',\n",
       " 'Fence',\n",
       " 'MiscFeature']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valores faltantes en X: Trabajaremos con columnas completas, sin valores faltantes.\n",
    "# Identificamos en \"cols_with_missing\" las columnas con valores faltantes para luego eliminarlas\n",
    "cols_with_missing = [col for col in X.columns\n",
    "                     if X[col].isnull().any()]\n",
    "cols_with_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminaremos las columnas con valores faltantes tanto en X como en X_test\n",
    "X.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_test.drop(cols_with_missing, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño de X: (filas, columnas) es: (1460, 60)\n",
      "El tamaño de X_test: (filas, columnas) es: (1459, 60)\n"
     ]
    }
   ],
   "source": [
    "# Tamaño de X, X_test despues de eliminar columnas con valores faltantes\n",
    "print(f\"El tamaño de X: (filas, columnas) es: {X.shape}\")\n",
    "print(f\"El tamaño de X_test: (filas, columnas) es: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataframe X tiene 0 columnas con valores nulos.\n"
     ]
    }
   ],
   "source": [
    "# Contar columnas con valores faltantes en X\n",
    "informar_columnas_nulas(X, \"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataframe X_test tiene 15 columnas con valores nulos.\n"
     ]
    }
   ],
   "source": [
    "# Contar columnas con valores faltantes en X\n",
    "informar_columnas_nulas(X_test, \"X_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se han eliminados las columnas con valores faltantes de X.\n",
    "* Esas mismas columnas se ha eliminado tambien de X_test. \n",
    "* Sin embargo, no olvidemos que aun quedan columnas con valores vacios en X_test. \n",
    "* Al preprocesar X_test, las columnas con valores faltantes se deben imputar, más no eliminarse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separe el conjunto de validación de los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar el conjunto de validación del conjunto de entrenamiento\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                      train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>11694</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NridgHt</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>6600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>13360</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>13265</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>13704</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSSubClass MSZoning  LotArea Street LotShape LandContour Utilities  \\\n",
       "Id                                                                        \n",
       "619          20       RL    11694   Pave      Reg         Lvl    AllPub   \n",
       "871          20       RL     6600   Pave      Reg         Lvl    AllPub   \n",
       "93           30       RL    13360   Pave      IR1         HLS    AllPub   \n",
       "818          20       RL    13265   Pave      IR1         Lvl    AllPub   \n",
       "303          20       RL    13704   Pave      IR1         Lvl    AllPub   \n",
       "\n",
       "    LotConfig LandSlope Neighborhood  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "Id                                    ...                                       \n",
       "619    Inside       Gtl      NridgHt  ...         108             0         0   \n",
       "871    Inside       Gtl        NAmes  ...           0             0         0   \n",
       "93     Inside       Gtl      Crawfor  ...           0            44         0   \n",
       "818   CulDSac       Gtl      Mitchel  ...          59             0         0   \n",
       "303    Corner       Gtl      CollgCr  ...          81             0         0   \n",
       "\n",
       "    ScreenPorch  PoolArea  MiscVal  MoSold  YrSold SaleType SaleCondition  \n",
       "Id                                                                         \n",
       "619         260         0        0       7    2007      New       Partial  \n",
       "871           0         0        0       8    2009       WD        Normal  \n",
       "93            0         0        0       8    2009       WD        Normal  \n",
       "818           0         0        0       7    2008       WD        Normal  \n",
       "303           0         0        0       1    2006       WD        Normal  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimimos las primeras cinco filas de datos.\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se observa que el conjunto de datos **contiene variables numéricas y categóricas.**\n",
    "* El siguiente paso es **codificar los datos categóricos antes de entrenar un modelo.**\n",
    "* **Se compararan** los diferentes modelos, con la función **score_dataset()**.\n",
    "* Esta función informa el error absoluto medio (MAE) de un modelo de bosque aleatorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para comparar los diferentes modelos para tratar datos categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para comparar los diferentes modelos para tratar datos categóricos\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enfoques para gestionar datos categóricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enfoque 1: Eliminar columnas con datos *categóricos*\n",
    "* Este es el enfoque más sencillo.\n",
    "\n",
    "**Paso 1**\n",
    "* Se preprocesan los datos en **X_train y X_valid** para eliminar columnas con datos categóricos (dtypes = 'object')\n",
    "* Recordemos que el tipo de dato **\"object\"** indica que una columna tiene texto (en teoría, hay otras cosas que podrían ser, pero eso no es importante para nuestros propósitos).\n",
    "* Se establecen los DataFrames preprocesados en **drop_X_train** y **drop_X_valid**, respectivamente\n",
    "\n",
    "**Paso 2**\n",
    "* Se obtiene el MAE para este enfoque a traves de la funcion **\"score_dataset\"** y los df **drop_X_train** y **drop_X_valid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Elimnamos las columnas con valores categoricos (dtypes=object) en X_train y X_valid, con el método select_dtypes().\n",
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño de drop_X_train: (filas, columnas) es: (1168, 33)\n",
      "El tamaño de drop_X_valid: (filas, columnas) es: (292, 33)\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Tamaño de X_train, X_valid despues de eliminar columnas con valores categóricos\n",
    "print(f\"El tamaño de drop_X_train: (filas, columnas) es: {drop_X_train.shape}\")\n",
    "print(f\"El tamaño de drop_X_valid: (filas, columnas) es: {drop_X_valid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Del total de 60 columnas, quedan solo las numericas (33).\n",
    "* El resto, 27 columnas categoricas, fueron eliminadas.\n",
    "* Con esta data se correrá el primer enfoque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Eliminar variables categóricas):\n",
      "17837.82570776256\n"
     ]
    }
   ],
   "source": [
    "# 2. Obtener el MAE para este enfoque.\n",
    "print(\"MAE from Approach 1 (Eliminar variables categóricas):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enfoque 2: codificación ordinal\n",
    "### **Parte A**: X_valid subconjunto de X_train\n",
    "* El conjunto de valores categoricos de validación debe estar contenido en el conjunto de valores categoricos de entrenamiento.\n",
    "* Esto es, revisar que los datos de validación contengan los mismos valores categoricos que aparecen en los datos de entrenamiento.\n",
    "* Antes de pasar al enfoque **codificación ordinal**, preprocesamos los conjuntos de datos.\n",
    "* Ajustar un codificador ordinal a una columna de los datos de entrenamiento crea una etiqueta de valor entero correspondiente para cada valor único que aparece en los datos de entrenamiento.\n",
    "* El codificador ordinal actua como una función que asigna una etiqueta de valor entero para cada valor unico que aparece en los datos de entrenamiento.  \n",
    "* En el caso de que los datos de validación contengan valores que no aparecen también en los datos de entrenamiento, el codificador arrojará un error, porque estos valores no tendrán un número entero asignado.\n",
    "* Como ejemplo, observamos que la columna '**Condición2**' en los datos de validación contiene los valores **'RRAn' y 'RRNn'**, pero estos no aparecen en los datos de entrenamiento; por lo tanto, si intentamos usar un codificador ordinal con scikit-learn, el código arrojará el error: \"se encontraron categorías desconocidas durante la transformación.\" ['RRNn', 'RRAn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Condition2' column in training data: ['Norm' 'PosA' 'Feedr' 'PosN' 'Artery' 'RRAe']\n",
      "\n",
      "Unique values in 'Condition2' column in validation data: ['Norm' 'RRAn' 'RRNn' 'Artery' 'Feedr' 'PosN']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in 'Condition2' column in training data:\", X_train['Condition2'].unique())\n",
    "print(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['Condition2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Este es un problema común y existen muchos enfoques para solucionarlo.\n",
    "* Por ejemplo, se puede escribir un codificador ordinal personalizado para manejar nuevas categorías.\n",
    "* Sin embargo, el enfoque más sencillo es **eliminar las columnas categóricas problemáticas.**\n",
    "\n",
    "Pasos:\n",
    "  * Listamos todas las columnas categóricas de los datos de entrenamiento.\n",
    "  * Guardamos en una lista de Python las columnas que pueden codificarse como ordinal de forma segura en **good_label_cols**.\n",
    "  * Del mismo modo, las columnas problemáticas se almacenan en la lista **bad_label_cols.**, para luego ser eliminadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de datos: Determinar columnas categóricas seguras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Hallar todas las Columnas categóricas en los datos de entrenamiento.\n",
    "object_cols = [col for col in X_train.columns\n",
    "               if X_train[col].dtype == \"object\"]\n",
    "\n",
    "\n",
    "# 2. Columnas a las que se puede aplicar codificación ordinal de forma segura\n",
    "# Asegurar que el dataset de Validacion es subconjunto del dataset de entrenamiento.\n",
    "good_label_cols = [col for col in object_cols if\n",
    "                   set(X_valid[col]).issubset(set(X_train[col]))]\n",
    "\n",
    "# 3. Columnas problemáticas que se eliminarán del conjunto de datos\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas categóricas que se codificarán como ordinales: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'BldgType', 'HouseStyle', 'RoofStyle', 'Exterior1st', 'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
      "\n",
      "Columnas categóricas que se eliminarán del conjunto de datos: ['Condition2', 'Functional', 'RoofMatl']\n"
     ]
    }
   ],
   "source": [
    "print('Columnas categóricas que se codificarán como ordinales:', good_label_cols)\n",
    "print('\\nColumnas categóricas que se eliminarán del conjunto de datos:', bad_label_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ya tenemos identificadas las columnas que se utilizaran para el metodo de codificaciòn ordinal. (Las columnas good_label_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte B : codificar ordinalmente los datos en X_train y X_valid.\n",
    "Se trabaja sobre los conjuntos de datos: **X_train y X_valid**.\n",
    "\n",
    "1. Se eliminan las columnas categóricas en **bad_label_cols** del conjunto de datos, preprocesando **X_train** y **X_valid** en **label_X_train** y **label_X_valid**, respectivamente. \n",
    "2. Se codifica de forma ordinal las columnas categóricas en **good_label_cols**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Eliminar columnas categóricas que no serán codificadas (bad_label_cols)\n",
    "# Guardar label_X_train y label_X_valid, respectivamente. \n",
    "\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño de label_X_train: (filas, columnas) es: (1168, 57)\n",
      "El tamaño de label_X_valid: (filas, columnas) es: (292, 57)\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Tamaño label_X_train y label_X_valid despues de eliminar columnas categóricas problemáticas.\n",
    "print(f\"El tamaño de label_X_train: (filas, columnas) es: {label_X_train.shape}\")\n",
    "print(f\"El tamaño de label_X_valid: (filas, columnas) es: {label_X_valid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se ha eliminado las tres columnas problemáticas: ['Condition2', 'Functional', 'RoofMatl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Aplicar codificador ordinal a las columnas buenas.(good_label_cols)\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "label_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\n",
    "label_X_valid[good_label_cols] = ordinal_encoder.transform(X_valid[good_label_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Ordinal Encoding):\n",
      "17098.01649543379\n"
     ]
    }
   ],
   "source": [
    "# 3. Obtener el MAE para este enfoque.\n",
    "print(\"MAE from Approach 2 (Ordinal Encoding):\")\n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enfoque 3: codificaciòn one-hot.\n",
    "* Hasta ahora, se han probado dos enfoques diferentes para tratar con variables categóricas.\n",
    "* Y se ha visto que codificar datos categóricos produce mejores resultados que eliminar columnas del conjunto de datos.\n",
    "* Antes de **probar la codificación one-hot**, hay un tema previo: **la cardinalidad**.\n",
    "* Esto es, la cantidad de entradas únicas en cada columna con datos categóricos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte A**. Investigar la cardinalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Street', 2),\n",
       " ('Utilities', 2),\n",
       " ('CentralAir', 2),\n",
       " ('LandSlope', 3),\n",
       " ('PavedDrive', 3),\n",
       " ('LotShape', 4),\n",
       " ('LandContour', 4),\n",
       " ('ExterQual', 4),\n",
       " ('KitchenQual', 4),\n",
       " ('MSZoning', 5),\n",
       " ('LotConfig', 5),\n",
       " ('BldgType', 5),\n",
       " ('ExterCond', 5),\n",
       " ('HeatingQC', 5),\n",
       " ('Condition2', 6),\n",
       " ('RoofStyle', 6),\n",
       " ('Foundation', 6),\n",
       " ('Heating', 6),\n",
       " ('Functional', 6),\n",
       " ('SaleCondition', 6),\n",
       " ('RoofMatl', 7),\n",
       " ('HouseStyle', 8),\n",
       " ('Condition1', 9),\n",
       " ('SaleType', 9),\n",
       " ('Exterior1st', 15),\n",
       " ('Exterior2nd', 16),\n",
       " ('Neighborhood', 25)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Cradinalidad: Obtener la cantidad de entradas únicas en cada columna con datos categóricos\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# 1.1 Imprimir el número de entradas únicas por columna, en orden ascendente\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Las 27 columnas con sus respectivos valores unicos en cada una de ellas.(Cardinalidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El resultado anterior muestra, para cada columna con datos categóricos, el número de valores únicos en la columna.\n",
    "* Por ejemplo, la columna \"Street\" en los datos de entrenamiento tiene dos valores únicos: \"Grvl\" y \"Pave\", correspondientes a un camino de grava y un camino pavimentado, respectivamente.\n",
    "* Nos referimos al número de entradas únicas de una variable categórica como la cardinalidad de esa variable categórica.\n",
    "* Por ejemplo, la variable 'Street' tiene cardinalidad 2 y one-hot ceará 2 columnas adicionales, una por cada categoría de la variable.\n",
    "* En ese sentido, para codificar con one-hot la variable Neighborhood, se necesitan 25 nuevas columnas. \n",
    "* Para codificar una columna categórica con codificación one-hot, se crea una nueva columna binaria para cada valor único en la columna original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte B**.  Seleccionar columnas con cardinalidad menor que 10 para codificarlas con one-hot.\n",
    "* Para conjuntos de datos grandes con muchas filas, la codificación one-hot puede ampliar considerablemente el tamaño del conjunto de datos.\n",
    "* Por esta razón, normalmente solo codificaremos con **one-hot** columnas con una **cardinalidad relativamente baja**.\n",
    "* Luego, las columnas de **alta cardinalidad** se pueden eliminar del conjunto de datos o podemos **usar codificación ordinal**.\n",
    "* En este sentido, en lugar de codificar todas las variables categóricas en el conjunto de datos, **solo se creará una codificación única para columnas con cardinalidad menor que 10**.\n",
    "* Para ello, se configura **low_cardinality_cols** en una lista de Python que contenga las columnas que se codificarán con one-hot.\n",
    "* Asimismo, **high_cardinality_cols** contiene una lista de columnas categóricas que se eliminarán del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Columnas que se codificarán con one-hot (cardinalidad menor que 10)\n",
    "low_cardinality_cols = [col for col in object_cols\n",
    "                        if X_train[col].nunique() < 10]\n",
    "\n",
    "# 2. Columnas que se eliminarán del conjunto de datos (cardinalidad mayor que 10)\n",
    "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas categóricas que se codificarán con one-hot: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'Functional', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
      "\n",
      "Columnas que se eliminarán del conjunto de datos: ['Exterior1st', 'Neighborhood', 'Exterior2nd']\n"
     ]
    }
   ],
   "source": [
    "print('Columnas categóricas que se codificarán con one-hot:', low_cardinality_cols)\n",
    "print('\\nColumnas que se eliminarán del conjunto de datos:', high_cardinality_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte C: codificación one-hot\n",
    "\n",
    "* Usamos la clase **OneHotEncoder** de scikit-learn para obtener codificaciones one-hot.\n",
    "* Hay una serie de parámetros que se pueden utilizar para personalizar su comportamiento.\n",
    "* Configuramos **handle_unknown='ignore'** para evitar errores cuando los datos de validación contienen clases que no están representadas en los datos de entrenamiento, y establecer **sparse=False** garantiza que las columnas codificadas se devuelvan como una matriz numerosa (en lugar de una matriz dispersa).\n",
    "* Para usar el codificador, **proporcionamos solo las columnas categóricas que queremos que se codifiquen como one-hot**.\n",
    "* Por ejemplo, para codificar los datos de entrenamiento, proporcionamos X_train[object_cols]. (object_cols es una lista de los nombres de columnas con datos categóricos, por lo que X_train[object_cols] contiene todos los datos categóricos en el conjunto de entrenamiento).\n",
    "\n",
    "**Funcionamiento**:\n",
    "* Esta clase de scikit-learn transforma variables categóricas en un conjunto de variables binarias, donde cada categoría se representa con una columna que toma valores binarios (0 ó 1).\n",
    "\n",
    "**Mejores prácticas**:\n",
    "* Adecuado cuando las variables categóricas no tienen un orden natural o cuando se quiere evitar la introducción de un orden artificial.\n",
    "\n",
    "**Ventajas**:\n",
    "* Evita la asignación de un orden artificial a las categorías y es compatible con una amplia gama de modelos de aprendizaje automático.\n",
    "\n",
    "**Desventajas**:\n",
    "* Puede generar un gran número de columnas adicionales, lo que aumenta la complejidad del conjunto de datos y puede afectar el rendimiento de ciertos modelos, especialmente si tienes muchas categorías únicas.\n",
    "\n",
    "Pasos:\n",
    "\n",
    "* Como sabemos, se codifica con one-hot los datos en **X_train** y **X_valid**.\n",
    "* 1. Una vez definido OneHotEncoder(), se aplica tanto a **X_train** como en **X_valid** solo a las columnas columnas categóricas definidas en la lista **low_cardinality_cols**, y se guardan en **OH_cols_train** y **OH_cols_valid**, respectivamente.\n",
    "* 2. Luego, se renombran las columnas resultantes despues de la codificación.\n",
    "* 3. Se seleccionan las columnas numéricas, (tipo 'int64' / 'float64') preprocesandolas en **num_X_train** y **num_X_valid**, eliminando el resto de todas las demás columnas categóricas del conjunto de datos.\n",
    "* 4. Se juntan en **OH_X_train** y **OH_X_valid**, respectivamente, las columnas codificadas one-hot(OH_cols_train y OH_cols_valid) a las funciones numéricas(num_X_train y num_X_valid)\n",
    "* 5. Asegurarse de que todas las columnas tengan tipo string (str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (One_Hot):\n",
      "17525.345719178084\n"
     ]
    }
   ],
   "source": [
    "# 1. Aplicar codificador one-hot a cada columna con datos categóricos con cardinalidad menor que 10\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False) # `sparse` was renamed to `sparse_output`\n",
    "\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n",
    "\n",
    "# 2. Se renombran las columnas (one-hot elimina los nombres)\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# 3. Defnir variables numéricas en num_X_train, num_X_valid\n",
    "# Eliminando de X_train y X_valid, el resto de columnas categoricas\n",
    "\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# 4. Juntar las columnas codificadas one-hot(OH_cols_train y OH_cols_valid) a las funciones numéricas\n",
    "# 4.bis Almacenarlas en las nuevas variables: OH_X_train y OH_X_valid\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "# 5. Asegúrese de que todas las columnas tengan tipo string (str)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "\n",
    "# 6. Obtener el MAE para este enfoque.\n",
    "print(\"MAE from Approach 3 (One_Hot):\")\n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop categorical variables):\n",
      "17837.82570776256\n",
      "MAE from Approach 2 (Ordinal Encoding):\n",
      "17098.01649543379\n",
      "MAE from Approach 3 (One_Hot):\n",
      "17525.345719178084\n"
     ]
    }
   ],
   "source": [
    "# MAE para enfoque Drop categorical variables\n",
    "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))\n",
    "\n",
    "# MAE para enfoque Ordinal Encoding\n",
    "print(\"MAE from Approach 2 (Ordinal Encoding):\")\n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))\n",
    "\n",
    "# MAE para enfoque One_Hot.\n",
    "print(\"MAE from Approach 3 (One_Hot):\")\n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El enfoque que generó menor MAE fue **Ordinal Encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar predicciones de prueba. (X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Parte A. Preprocesar los datos de entrenamiento y validación.\n",
    "* Utilizar un método que coincida con la forma en que se procesó previamente los datos de entrenamiento y validación.\n",
    "  * En este caso, utilizamos el enfoque para tratar variables categóricas que resultó con menor valor MAE:  **codificación ordinal**\n",
    "  * Recordemos que sus variables son **label_X_train** y **label_X_valid**\n",
    "  * La codificación ordinal se ejecutó sobre las columnas buenas contenidas en la lista: **good_label_cols**\n",
    "* Utilizar las funciones de validación y entrenamiento ya preprocesadas.\n",
    "* Establezca los DataFrames preprocesados en **final_X_train** y **final_X_valid**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Los resultados obtenidas por el enfoque de codificación ordinal fueron los mejores.\n",
    "# Los elegimos para nuestro modelo final y se definen las variables finales.\n",
    "final_X_train = label_X_train\n",
    "final_X_valid = label_X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Revisar las mismas columnas en los dataframe de entrenamiento y validación\n",
    "# Función para comparar columnas en dos dataframe\n",
    "\n",
    "def comparar_columnas(df_a, df_b, nombre_df_a, nombre_df_b, considerar_orden=False):\n",
    "    \"\"\"\n",
    "    Compara si dos DataFrames tienen los mismos nombres de columnas.\n",
    "\n",
    "    Parámetros:\n",
    "    df_a (pd.DataFrame): Primer DataFrame.\n",
    "    df_b (pd.DataFrame): Segundo DataFrame.\n",
    "    nombre_df_a (str): Nombre del primer DataFrame para imprimir en el mensaje.\n",
    "    nombre_df_b (str): Nombre del segundo DataFrame para imprimir en el mensaje.\n",
    "    considerar_orden (bool): Si se debe considerar el orden de las columnas.\n",
    "\n",
    "    Retorna:\n",
    "    bool: True si los DataFrames tienen las mismas columnas, False en caso contrario.\n",
    "    \"\"\"\n",
    "    if considerar_orden:\n",
    "        # Verificar si el orden de las columnas es el mismo\n",
    "        mismas_columnas = list(df_a.columns) == list(df_b.columns)\n",
    "    else:\n",
    "        # Verificar si los conjuntos de columnas son iguales, sin considerar el orden\n",
    "        mismas_columnas = set(df_a.columns) == set(df_b.columns)\n",
    "\n",
    "    if mismas_columnas:\n",
    "        print(f\"Los DataFrames '{nombre_df_a}' y '{nombre_df_b}' tienen las mismas columnas iguales a {df_a.shape[1]}.\")\n",
    "    else:\n",
    "        columnas_df_a = set(df_a.columns)\n",
    "        columnas_df_b = set(df_b.columns)\n",
    "        columnas_faltantes_a = columnas_df_b - columnas_df_a\n",
    "        columnas_faltantes_b = columnas_df_a - columnas_df_b\n",
    "\n",
    "        print(f\"Los DataFrames '{nombre_df_a}' y '{nombre_df_b}' NO tienen las mismas columnas.\")\n",
    "        if columnas_faltantes_a:\n",
    "            print(f\"Columnas en '{nombre_df_b}' que faltan en '{nombre_df_a}': {columnas_faltantes_a}\")\n",
    "        if columnas_faltantes_b:\n",
    "            print(f\"Columnas en '{nombre_df_a}' que faltan en '{nombre_df_b}': {columnas_faltantes_b}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los DataFrames 'final_X_train' y 'final_X_valid' tienen las mismas columnas iguales a 57.\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Revisar las mismas columnas en los dataframe de entrenamiento y validación\n",
    "comparar_columnas(final_X_train, final_X_valid, 'final_X_train', 'final_X_valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Revisar que no existan valores faltantes en los dataframe\n",
    "# Función para verificar valores fantanes en un dataframe\n",
    "def verificar_valores_faltantes(df, nombre_df ):\n",
    "    # Verificar si hay valores faltantes en el DataFrame\n",
    "    faltantes = df.isnull().values.any()\n",
    "\n",
    "    # Imprimir resultado\n",
    "    if not faltantes:\n",
    "        print(f\"El DataFrame '{nombre_df}' no tiene valores faltantes.\")\n",
    "    else:\n",
    "        print(f\"El DataFrame '{nombre_df}' tiene valores faltantes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame 'final_X_train' no tiene valores faltantes.\n",
      "El DataFrame 'final_X_valid' no tiene valores faltantes.\n"
     ]
    }
   ],
   "source": [
    "verificar_valores_faltantes(final_X_train, \"final_X_train\")\n",
    "verificar_valores_faltantes(final_X_valid, \"final_X_valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_X_train tiene 1168 filas\n",
      "y_train tiene 1168 filas\n"
     ]
    }
   ],
   "source": [
    "# 3.Revisar que final_X_train tiene el mismo número de filas que y_train\n",
    "print(f\"final_X_train tiene {final_X_train.shape[0]} filas\")\n",
    "print(f\"y_train tiene {y_train.shape[0]} filas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_X_valid tiene 292 filas\n",
      "y_valid tiene 292 filas\n"
     ]
    }
   ],
   "source": [
    "# 4. Revisar que final_X_valid tiene el mismo número de filas que y_valid\n",
    "print(f\"final_X_valid tiene {final_X_valid.shape[0]} filas\")\n",
    "print(f\"y_valid tiene {y_valid.shape[0]} filas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte B: Entrenar y validar el modelo final de ML (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Definir y ajustar las variables finales en el modelo entrenado\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model.fit(final_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Codificación Ordinal):\n",
      "17098.01649543379\n"
     ]
    }
   ],
   "source": [
    "# 6. Obtener predicciones de validación y MAE\n",
    "preds_valid = model.predict(final_X_valid)\n",
    "print(\"MAE (Codificación Ordinal):\")\n",
    "print(mean_absolute_error(y_valid, preds_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte C. Preprocesar los datos de prueba (X_test)\n",
    "\n",
    "1. Utilizar un método que coincida con la forma en que procesó previamente los datos de entrenamiento y validación.\n",
    "  * En este caso, recordemos que utilizamos el enfoque para tratar variables categóricas que resultó con menor valor MAE:  **codificación ordinal**\n",
    "  * Sus variables son **label_X_train** y **label_X_valid**\n",
    "  * La codificación ordinal se ejecutó sobre las columnas buenas contenidas en la lista: **good_label_cols**\n",
    "2. Configure las funciones de prueba preprocesadas en **final_X_test**.\n",
    "3. Utilice las funciones de prueba preprocesadas y el modelo entrenado para generar predicciones de prueba en **preds_test**.\n",
    "4. Asegurarse de:\n",
    "\n",
    "  4.1 el DataFrame de prueba preprocesado no tiene valores faltantes,\n",
    "\n",
    "  4.2 final_X_test tiene el mismo número de filas que X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test, tiene 1459 filas y 60 columnas\n"
     ]
    }
   ],
   "source": [
    "# 1 Tamaño de X_test\n",
    "print(f\"X_test, tiene {X_test.shape[0]} filas y {X_test.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Condition2', 'Functional', 'RoofMatl']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Eliminar de X_test las columnas categoricas \"bad_label_cols\" que se eliminaron para entrenar el modelo\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "bad_label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Eliminar en X_test, las columnas categóricas que no serán codificadas (bad_label_cols)\n",
    "# El resultado se almacena en X_test_0\n",
    "\n",
    "X_test_0 = X_test.drop(bad_label_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_0, tiene 1459 filas y 57 columnas\n"
     ]
    }
   ],
   "source": [
    "# Tamaño de X_test_0\n",
    "print(f\"X_test_0, tiene {X_test_0.shape[0]} filas y {X_test_0.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los DataFrames 'label_X_train' y 'X_test_0' tienen las mismas columnas iguales a 57.\n"
     ]
    }
   ],
   "source": [
    "# Los dataframe label_X_train, X_test_0 tienen las mismas columnas\n",
    "comparar_columnas(label_X_train, X_test_0, 'label_X_train', 'X_test_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataframe X_test_0 tiene 14 columnas con valores nulos.\n"
     ]
    }
   ],
   "source": [
    "# 2 Buscar columnas con valores faltantes en X_test_0\n",
    "informar_columnas_nulas(X_test_0, 'X_test_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El modelo fue entrenado con las 57 columnas que ambos dataframe comparten. \n",
    "* En este sentido, no aplica eliminar columnas con valores faltantes en X_test_0, ya que ellas definieron al modelo ya definido de ML.\n",
    "* Se debe aplicar tratamiento de valores faltantes a traves del metodo de imputación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestión de valores faltantes en el dataframe X_test_0: Método de imputación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Se imputa sobre X_test_0 y se guardan los resultados en imputed_X_test\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "mi_imputacion = SimpleImputer(strategy='most_frequent') # strategy='most_frequent', dado que aplica tanto para var numéricas y categóricas. \n",
    "\n",
    "imputed_X_test = pd.DataFrame(mi_imputacion.fit_transform(X_test_0))\n",
    "\n",
    "# 2. Devolver nombre a columnas eliminadas por la imputación.\n",
    "\n",
    "imputed_X_test.columns = X_test_0.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputed_X_test, tiene 1459 filas y 57 columnas\n"
     ]
    }
   ],
   "source": [
    "# 3. Tamaño de imputed_X_test\n",
    "print(f\"imputed_X_test, tiene {imputed_X_test.shape[0]} filas y {imputed_X_test.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataframe imputed_X_test tiene 0 columnas con valores nulos.\n"
     ]
    }
   ],
   "source": [
    "# 4. revisar columnas con valores faltantes en imputed_X_test\n",
    "informar_columnas_nulas(imputed_X_test, 'imputed_X_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicar OrdinalEncoder() en el dataframe imputed_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSSubClass',\n",
       " 'MSZoning',\n",
       " 'LotArea',\n",
       " 'Street',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'OverallQual',\n",
       " 'OverallCond',\n",
       " 'YearBuilt',\n",
       " 'YearRemodAdd',\n",
       " 'RoofStyle',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtFinSF1',\n",
       " 'BsmtFinSF2',\n",
       " 'BsmtUnfSF',\n",
       " 'TotalBsmtSF',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " '1stFlrSF',\n",
       " '2ndFlrSF',\n",
       " 'LowQualFinSF',\n",
       " 'GrLivArea',\n",
       " 'BsmtFullBath',\n",
       " 'BsmtHalfBath',\n",
       " 'FullBath',\n",
       " 'HalfBath',\n",
       " 'BedroomAbvGr',\n",
       " 'KitchenAbvGr',\n",
       " 'KitchenQual',\n",
       " 'TotRmsAbvGrd',\n",
       " 'Fireplaces',\n",
       " 'GarageCars',\n",
       " 'GarageArea',\n",
       " 'PavedDrive',\n",
       " 'WoodDeckSF',\n",
       " 'OpenPorchSF',\n",
       " 'EnclosedPorch',\n",
       " '3SsnPorch',\n",
       " 'ScreenPorch',\n",
       " 'PoolArea',\n",
       " 'MiscVal',\n",
       " 'MoSold',\n",
       " 'YrSold',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Identificar las columnas categóricas en imputed_X_test\n",
    "object_cols_test = [col for col in imputed_X_test.columns\n",
    "                    if imputed_X_test[col].dtype == \"object\"]\n",
    "object_cols_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los DataFrames 'label_X_train' y 'imputed_X_test' tienen las mismas columnas iguales a 57.\n"
     ]
    }
   ],
   "source": [
    "# 2 Verificar que los dataframe 'label_X_train' y 'imputed_X_test' tienen las mismas columnas.\n",
    "# label_X_train fue el dataframe con el cual se definió el Modelo de ML final. \n",
    "comparar_columnas(label_X_train, imputed_X_test, 'label_X_train', 'imputed_X_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataframe imputed_X_test tiene 0 columnas con valores nulos.\n"
     ]
    }
   ],
   "source": [
    "# 3 Revisar valores faltantes en imputed_X_test\n",
    "informar_columnas_nulas(imputed_X_test,'imputed_X_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Aplicar codificador ordinal en imputed_X_test a las columnas buenas del modelo entrenado.(good_label_cols)\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "imputed_X_test[good_label_cols] = ordinal_encoder.fit_transform(imputed_X_test[good_label_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Preprocesar Data de prueba con el mismo método ya imputado\n",
    "final_X_test = imputed_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([127289.08, 156450.  , 179283.14, ..., 152192.4 , 110848.33,\n",
       "       229718.22])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.Obtener la prediciòn de prueba\n",
    "preds_test = model.predict(final_X_test)\n",
    "preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Guardar el archivo \n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
